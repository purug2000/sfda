{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from transformers.data.processors.utils import InputExample, InputFeatures\n",
    "from transformers.data.processors.glue import glue_convert_examples_to_features\n",
    "from transformers.data.processors.utils import DataProcessor\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from sfda.models import sfdaSourceRobertaNegation\n",
    "from sfda.trainer import sfdaTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"-1\", \"1\"]\n",
    "max_length = 128\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegationDataset(Dataset):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        self.label_list = [\"-1\", \"1\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, i) -> InputFeatures:\n",
    "        return self.features[i]\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.label_list\n",
    "\n",
    "    @classmethod\n",
    "    def from_tsv(cls, tsv_file, tokenizer):\n",
    "        \"\"\"Creates examples for the test set.\"\"\"\n",
    "        lines = DataProcessor._read_tsv(tsv_file)\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            guid = 'instance-%d' % i\n",
    "            if line[0] in labels:\n",
    "                text_a = '\\t'.join(line[1:])\n",
    "            else:\n",
    "                text_a = '\\t'.join(line)\n",
    "\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=None))\n",
    "\n",
    "        features = glue_convert_examples_to_features(\n",
    "            examples,\n",
    "            tokenizer,\n",
    "            max_length=max_length,\n",
    "            label_list=labels,\n",
    "            output_mode='classification',\n",
    "        )\n",
    "        return cls(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file, output_dir = \"practice_text/train.tsv\", \"../outputs/negation/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"tmills/roberta_sfda_sharpseed\"# Base Model\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, config=config)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at tmills/roberta_sfda_sharpseed were not used when initializing sfdaSourceRobertaNegation: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing sfdaSourceRobertaNegation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing sfdaSourceRobertaNegation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = sfdaSourceRobertaNegation.from_pretrained(model_name,config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are instantiating a Trainer but Tensorboard is not installed. You should consider installing it.\n"
     ]
    }
   ],
   "source": [
    "# create a torch dataset from a tsv file\n",
    "test_dataset = NegationDataset.from_tsv(data_file, tokenizer)\n",
    "\n",
    "trainer = sfdaTrainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments('save_run/'),\n",
    "    compute_metrics=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af97a3e2e49147a1bbdccd153a4181d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Prediction'), FloatProgress(value=0.0, max=361.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_dict = trainer.predict(test_dataset=test_dataset,ret_feats = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = prediction_dict.predictions\n",
    "predictions = np.argmax(scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_matrix = prediction_dict.feat_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_test_file = os.path.join(output_dir, 'train_pred.tsv')\n",
    "feat_matrix_file = os.path.join(output_dir, 'train_scores_and_feat_mat.npy')\n",
    "with open(output_test_file, \"w\") as writer:\n",
    "    logger.info(\"***** Test results *****\")\n",
    "    for index, item in enumerate(predictions):\n",
    "        item = test_dataset.get_labels()[item]\n",
    "#         print(\"%s\\n\" % item)\n",
    "        writer.write(\"%s\\n\" % item)\n",
    "with open(feat_matrix_file,'wb') as file:\n",
    "    np.save(file,feat_matrix)\n",
    "    np.save(file,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
